{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    },
    "colab": {
      "name": "CW1_GPU_3CONV.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/maxpilling/AI/blob/master/image_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IdnsT8VYCSYF",
        "colab_type": "text"
      },
      "source": [
        "## Image Classification with Convolutional Neural Networks "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eKS20wjsCSYI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as transforms\n",
        "from  torch.utils.data import Dataset\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from skimage import io, transform\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "from PIL import Image\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import csv\n",
        "import os\n",
        "import math\n",
        "import cv2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IpRGGlofCSYM",
        "colab_type": "text"
      },
      "source": [
        "### Part I"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EqhQboSCCSYN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "9a379806-ffbf-4077-9ba8-48f8c4bf7697"
      },
      "source": [
        "# ! rm -r imagenet10/\n",
        "! git clone https://github.com/MohammedAlghamdi/imagenet10.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'imagenet10'...\n",
            "remote: Enumerating objects: 10019, done.\u001b[K\n",
            "remote: Total 10019 (delta 0), reused 0 (delta 0), pack-reused 10019\u001b[K\n",
            "Receiving objects: 100% (10019/10019), 966.71 MiB | 25.02 MiB/s, done.\n",
            "Resolving deltas: 100% (2/2), done.\n",
            "Checking out files: 100% (10002/10002), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8edZnYShg7M1",
        "colab_type": "text"
      },
      "source": [
        "Check that the repository is there:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i2RIZGHaCVAC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0711886e-7eea-423c-ced6-5c6012032a90"
      },
      "source": [
        "! ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "imagenet10  sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "47tv-wIQCTcS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "root_dir = \"imagenet10/train_set/\"\n",
        "class_names = [\n",
        "  \"baboon\",\n",
        "  \"banana\",\n",
        "  \"canoe\",\n",
        "  \"cat\",\n",
        "  \"desk\",\n",
        "  \"drill\",\n",
        "  \"dumbbell\",\n",
        "  \"football\",\n",
        "  \"mug\",\n",
        "  \"orange\",\n",
        "]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L6oMdWl5CSYR",
        "colab_type": "text"
      },
      "source": [
        "A helper function for reading in images and assigning labels."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tQfcD3jyCSYT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_meta(root_dir, dirs):\n",
        "    \"\"\" Fetches the meta data for all the images and assigns labels.\n",
        "    \"\"\"\n",
        "    paths, classes = [], []\n",
        "    for i, dir_ in enumerate(dirs):\n",
        "        for entry in os.scandir(root_dir + dir_):\n",
        "            if (entry.is_file()):\n",
        "                paths.append(entry.path)\n",
        "                classes.append(i)\n",
        "                \n",
        "    return paths, classes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0J967KW0CSYX",
        "colab_type": "text"
      },
      "source": [
        "Now we create a dataframe using all the data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8gDPs1NCCSYY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Benign images we will assign class 0, and malignant as 1\n",
        "paths, classes = get_meta(root_dir, class_names)\n",
        "\n",
        "data = {\n",
        "    'path': paths,\n",
        "    'class': classes\n",
        "}\n",
        "\n",
        "data_df = pd.DataFrame(data, columns=['path', 'class'])\n",
        "data_df = data_df.sample(frac=1).reset_index(drop=True) # Shuffles the data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jRUDj3WihItY",
        "colab_type": "text"
      },
      "source": [
        "View some sample data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mK2GPzfVCSYc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "47e52bbc-65e2-41e6-d174-98a5350d339a"
      },
      "source": [
        "print(\"Found\", len(data_df), \"images.\")\n",
        "data_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 9000 images.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>path</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>imagenet10/train_set/canoe/n02951358_5118.JPEG</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>imagenet10/train_set/football/n04254680_5365.JPEG</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>imagenet10/train_set/orange/n07747607_4103.JPEG</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>imagenet10/train_set/mug/n03797390_5061.JPEG</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>imagenet10/train_set/canoe/n02951358_10047.JPEG</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                path  class\n",
              "0     imagenet10/train_set/canoe/n02951358_5118.JPEG      2\n",
              "1  imagenet10/train_set/football/n04254680_5365.JPEG      7\n",
              "2    imagenet10/train_set/orange/n07747607_4103.JPEG      9\n",
              "3       imagenet10/train_set/mug/n03797390_5061.JPEG      8\n",
              "4    imagenet10/train_set/canoe/n02951358_10047.JPEG      2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ai3uvziWCSYh",
        "colab_type": "text"
      },
      "source": [
        "Now we will create the Dataset class."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EyUb-rzQCSYi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ImageNet10(Dataset):\n",
        "    \"\"\" ImageNet10 dataset. \"\"\"\n",
        "\n",
        "    def __init__(self, df, transform=None):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            image_dir (string): Directory with all the images\n",
        "            df (DataFrame object): Dataframe containing the images, paths and classes\n",
        "            transform (callable, optional): Optional transform to be applied\n",
        "                on a sample.\n",
        "        \"\"\"\n",
        "        self.df = df\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        # Load image from path and get label\n",
        "        x = Image.open(self.df['path'][index])\n",
        "        try:\n",
        "          x = x.convert('RGB') # To deal with some grayscale images in the data\n",
        "        except:\n",
        "          pass\n",
        "        y = torch.tensor(int(self.df['class'][index]))\n",
        "\n",
        "        if self.transform:\n",
        "            x = self.transform(x)\n",
        "\n",
        "        return x, y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vqtRjBozCSYk",
        "colab_type": "text"
      },
      "source": [
        "Compute what we should normalise the dataset to."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pPqfMPuZCSYl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def compute_img_mean_std(image_paths):\n",
        "    \"\"\"\n",
        "        Author: @xinruizhuang. Computing the mean and std of three channel on the whole dataset,\n",
        "        first we should normalize the image from 0-255 to 0-1\n",
        "    \"\"\"\n",
        "\n",
        "    img_h, img_w = 224, 224\n",
        "    imgs = []\n",
        "    means, stdevs = [], []\n",
        "\n",
        "    for i in tqdm(range(len(image_paths))):\n",
        "        img = cv2.imread(image_paths[i])\n",
        "        img = cv2.resize(img, (img_h, img_w))\n",
        "        imgs.append(img)\n",
        "\n",
        "    imgs = np.stack(imgs, axis=3)\n",
        "    print(imgs.shape)\n",
        "\n",
        "    imgs = imgs.astype(np.float32) / 255.\n",
        "\n",
        "    for i in range(3):\n",
        "        pixels = imgs[:, :, i, :].ravel()  # resize to one row\n",
        "        means.append(np.mean(pixels))\n",
        "        stdevs.append(np.std(pixels))\n",
        "\n",
        "    means.reverse()  # BGR --> RGB\n",
        "    stdevs.reverse()\n",
        "\n",
        "    print(\"normMean = {}\".format(means))\n",
        "    print(\"normStd = {}\".format(stdevs))\n",
        "    return means, stdevs\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-_1KSGUe4sEW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "1d4ae6bc-bfa1-45a4-bb3b-bbc431f65e08"
      },
      "source": [
        "norm_mean, norm_std = compute_img_mean_std(paths)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 9000/9000 [00:43<00:00, 209.07it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(224, 224, 3, 9000)\n",
            "normMean = [0.52283835, 0.47988674, 0.40605244]\n",
            "normStd = [0.2977063, 0.28884053, 0.3117812]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RqrG3FCUCSYo",
        "colab_type": "text"
      },
      "source": [
        "Now let's create the transforms to normalise and turn our data into tensors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OVeZpgM-CSYq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_transform = transforms.Compose([\n",
        "        transforms.Resize(256),\n",
        "        transforms.CenterCrop(256),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(norm_mean, norm_std),\n",
        "    ])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cAPzCfr2CSYt",
        "colab_type": "text"
      },
      "source": [
        "Let's split the data into train and test sets and instantiate our new ISIC_Dataset objects."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "POCexxXjCSYu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_split = 0.70 # Defines the ratio of train/valid/test data.\n",
        "valid_split = 0.10\n",
        "\n",
        "train_size = int(len(data_df)*train_split)\n",
        "valid_size = int(len(data_df)*valid_split)\n",
        "\n",
        "ins_dataset_train = ImageNet10(\n",
        "    df=data_df[:train_size],\n",
        "    transform=data_transform,\n",
        ")\n",
        "\n",
        "ins_dataset_valid = ImageNet10(\n",
        "    df=data_df[train_size:(train_size + valid_size)].reset_index(drop=True),\n",
        "    transform=data_transform,\n",
        ")\n",
        "\n",
        "ins_dataset_test = ImageNet10(\n",
        "    df=data_df[(train_size + valid_size):].reset_index(drop=True),\n",
        "    transform=data_transform,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PzVfNzvmhTGJ",
        "colab_type": "text"
      },
      "source": [
        "You will need to create DataLoaders for the datasets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_womtSmIhgSj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_loader = torch.utils.data.DataLoader(\n",
        "    ins_dataset_train,\n",
        "    batch_size=16,\n",
        "    shuffle=True,\n",
        "    num_workers=2\n",
        ")\n",
        "\n",
        "valid_loader = torch.utils.data.DataLoader(\n",
        "    ins_dataset_valid,\n",
        "    batch_size=16,\n",
        "    shuffle=True,\n",
        "    num_workers=2\n",
        ")\n",
        "\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    ins_dataset_test,\n",
        "    batch_size=24,\n",
        "    shuffle=False,\n",
        "    num_workers=2\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X00vuzPWhY5h",
        "colab_type": "text"
      },
      "source": [
        "A framework for the ConvNet model, missing all layers except the final fully-connected layer:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3B5x07o3CSY7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Convolutional neural network\n",
        "class ConvNet(nn.Module):\n",
        "    \n",
        "    def __init__(self, num_classes=10):\n",
        "        super(ConvNet, self).__init__()\n",
        "  \n",
        "        # Add network layers here\n",
        "        self.cnn_layers = nn.Sequential(\n",
        "            # Convolution 1\n",
        "            nn.Conv2d(3, 16, kernel_size=(3,3)),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d((2,2)),\n",
        "            nn.Dropout(p=0.3),\n",
        "            \n",
        "            # Convolution 2\n",
        "            nn.Conv2d(16, 24, kernel_size=(4,4)),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d((2,2)),\n",
        "            nn.Dropout(p=0.3),\n",
        "\n",
        "            # Convolution 3\n",
        "            nn.Conv2d(24, 32, kernel_size=(4,4)),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d((2,2)),\n",
        "            nn.Dropout(p=0.3),\n",
        "\n",
        "            nn.Flatten(),\n",
        "        )\n",
        "\n",
        "        self.linear_layers = nn.Sequential(\n",
        "            nn.Linear(26912, 512),\n",
        "            nn.Linear(512, num_classes),\n",
        "        )\n",
        "\n",
        "        # self.final = nn.Softmax(dim=1)\n",
        "        \n",
        "    def forward(self, x):\n",
        "\n",
        "        # Complete the graph\n",
        "        out = self.cnn_layers(x)\n",
        "        out = self.linear_layers(out)\n",
        "        return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GBN2Os7KYket",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c92c3354-59f9-4aee-cf43-f90453171f5f"
      },
      "source": [
        "torch.manual_seed(0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7fbb4c0dc750>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JTeN1QJ5Ylme",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "outputId": "17e63dda-a9f2-48de-a4fa-e02747315010"
      },
      "source": [
        "model = ConvNet()\n",
        "model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ConvNet(\n",
              "  (cnn_layers): Sequential(\n",
              "    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1))\n",
              "    (1): ReLU()\n",
              "    (2): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
              "    (3): Dropout(p=0.3, inplace=False)\n",
              "    (4): Conv2d(16, 24, kernel_size=(4, 4), stride=(1, 1))\n",
              "    (5): ReLU()\n",
              "    (6): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
              "    (7): Dropout(p=0.3, inplace=False)\n",
              "    (8): Conv2d(24, 32, kernel_size=(4, 4), stride=(1, 1))\n",
              "    (9): ReLU()\n",
              "    (10): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
              "    (11): Dropout(p=0.3, inplace=False)\n",
              "    (12): Flatten()\n",
              "  )\n",
              "  (linear_layers): Sequential(\n",
              "    (0): Linear(in_features=26912, out_features=512, bias=True)\n",
              "    (1): Linear(in_features=512, out_features=10, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WT3aFsXueHMo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "dea433e2-5264-4a55-9d26-1529e55b1ff1"
      },
      "source": [
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1pTlyqMUeJD4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_gpu = ConvNet().to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YS0xiTpBYm0s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Stochastic gradient dforward(escent\n",
        "optimiser = optim.SGD(model_gpu.parameters(), lr=0.001, momentum=0.9)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fTyilaq0Yoid",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_model_epochs_wo_val(num_epochs):\n",
        "  for epoch in range(num_epochs):\n",
        "    print('Epoch {}/{}:'.format(epoch + 1, num_epochs))\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(train_loader, 0):\n",
        "      images, labels = data\n",
        "\n",
        "      # Explicitly specifies that data is to be copied onto the device!\n",
        "      images = images.to(device)  # <----------- And note it's NOT an in-place operation; original\n",
        "      labels = labels.to(device)  # <----------- variables still exist on CPU\n",
        "\n",
        "      # Zero the param gradients\n",
        "      optimiser.zero_grad()\n",
        "\n",
        "      # forward pass\n",
        "      outputs = model_gpu(images)\n",
        "\n",
        "      # compute loss\n",
        "      loss = criterion(outputs, labels)\n",
        "\n",
        "      # backwards pass (backpropagate the error wrt the lossforward)\n",
        "      loss.backward()\n",
        "\n",
        "      # update the parameters\n",
        "      optimiser.step()\n",
        "\n",
        "      # print the loss\n",
        "      running_loss += loss.item()\n",
        "      if i % 100 == 99:    # print every 100 mini-batches\n",
        "          print('Batch %d - Loss: %.3f' %\n",
        "                  (i + 1, running_loss / 100))\n",
        "          running_loss = 0.0\n",
        "\n",
        "  print('Saving model.')\n",
        "  if (os.path.exists('./3Conv_wo_val.pt')):\n",
        "    os.remove('./3Conv_wo_val.pt')\n",
        "  torch.save(model.state_dict(), './3Conv_wo_val.pt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NboZEIqZ4Dmm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_model_epochs_w_val(num_epochs):\n",
        "  best_val_loss = 100000\n",
        "  for epoch in range(num_epochs):\n",
        "    print('Epoch {}/{}:'.format(epoch + 1, num_epochs))\n",
        "    for phase in ['train', 'val']:\n",
        "        \n",
        "      if (phase == 'train'):\n",
        "        loader = train_loader\n",
        "      else:\n",
        "        loader = valid_loader\n",
        "\n",
        "      running_loss = 0.0\n",
        "\n",
        "      for i, data in enumerate(loader, 0):\n",
        "        images, labels = data\n",
        "\n",
        "        # Explicitly specifies that data is to be copied onto the device!\n",
        "        images = images.to(device)  # <----------- And note it's NOT an in-place operation; original\n",
        "        labels = labels.to(device)  # <----------- variables still exist on CPU\n",
        "\n",
        "        # Zero the param gradients\n",
        "        optimiser.zero_grad()\n",
        "\n",
        "        # forward pass\n",
        "        outputs = model_gpu(images)\n",
        "\n",
        "        # compute loss\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        if phase == 'train':\n",
        "          # backwards pass (backpropagate the error wrt the lossforward)\n",
        "          loss.backward()\n",
        "          # update the parameters\n",
        "          optimiser.step()\n",
        "\n",
        "        # print the loss\n",
        "        running_loss += loss.item()\n",
        "\n",
        "        if i % 100 == 99:    # print every 100 mini-batches\n",
        "            print('Batch %d - Loss: %.3f' %\n",
        "                  (i + 1, running_loss / 100))\n",
        "            running_loss = 0.0\n",
        "\n",
        "      if phase == 'val':\n",
        "          print('Validation loss: {}'.format(running_loss))\n",
        "          if (running_loss < best_val_loss):\n",
        "            print('Saving model.')\n",
        "            best_val_loss = running_loss\n",
        "            if (os.path.exists('./3Conv_w_val.pt')):\n",
        "              os.remove('./3Conv_w_val.pt')\n",
        "            torch.save(model.state_dict(), './3Conv_w_val.pt')\n",
        "          print('-' * 20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7V43IeLSYtlG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 714
        },
        "outputId": "be13278f-99ee-4a2d-b964-62cc163b936c"
      },
      "source": [
        "import timeit\n",
        "\n",
        "cpu_train_time = timeit.timeit(\n",
        "    \"train_model_epochs_wo_val(num_epochs)\",\n",
        "    setup=\"num_epochs=10\",\n",
        "    number=1,\n",
        "    globals=globals(),\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10:\n",
            "Batch 100 - Loss: 2.223\n",
            "Batch 200 - Loss: 1.970\n",
            "Batch 300 - Loss: 1.890\n",
            "Epoch 2/10:\n",
            "Batch 100 - Loss: 1.747\n",
            "Batch 200 - Loss: 1.692\n",
            "Batch 300 - Loss: 1.685\n",
            "Epoch 3/10:\n",
            "Batch 100 - Loss: 1.619\n",
            "Batch 200 - Loss: 1.629\n",
            "Batch 300 - Loss: 1.551\n",
            "Epoch 4/10:\n",
            "Batch 100 - Loss: 1.472\n",
            "Batch 200 - Loss: 1.510\n",
            "Batch 300 - Loss: 1.517\n",
            "Epoch 5/10:\n",
            "Batch 100 - Loss: 1.390\n",
            "Batch 200 - Loss: 1.403\n",
            "Batch 300 - Loss: 1.397\n",
            "Epoch 6/10:\n",
            "Batch 100 - Loss: 1.301\n",
            "Batch 200 - Loss: 1.306\n",
            "Batch 300 - Loss: 1.279\n",
            "Epoch 7/10:\n",
            "Batch 100 - Loss: 1.187\n",
            "Batch 200 - Loss: 1.140\n",
            "Batch 300 - Loss: 1.165\n",
            "Epoch 8/10:\n",
            "Batch 100 - Loss: 0.998\n",
            "Batch 200 - Loss: 1.068\n",
            "Batch 300 - Loss: 1.043\n",
            "Epoch 9/10:\n",
            "Batch 100 - Loss: 0.957\n",
            "Batch 200 - Loss: 0.887\n",
            "Batch 300 - Loss: 0.956\n",
            "Epoch 10/10:\n",
            "Batch 100 - Loss: 0.747\n",
            "Batch 200 - Loss: 0.843\n",
            "Batch 300 - Loss: 0.834\n",
            "Saving model.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M2Xd2gsOYwXS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "163ad95f-d764-42ff-e1a7-eef4f1080db1"
      },
      "source": [
        "cpu_train_time"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "475.915616662"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GOBEx-iEnrHZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ConvNet = torch.load('./3Conv_wo_val.pt',  map_location=lambda storage, loc: storage)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VJCdZKIrY0Ok",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "be031aad-18b4-4af1-e281-fb49b3e79125"
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "tot_predicted = torch.zeros(0,dtype=torch.long, device='cpu')\n",
        "tot_labels    = torch.zeros(0,dtype=torch.long, device='cpu')\n",
        "# tot_predicted = torch.Tensor()\n",
        "# Why don't we need gradients? What happens if we do include gradients?\n",
        "with torch.no_grad():\n",
        "    # Iterate over the test set\n",
        "    i = 0\n",
        "    for i, data in enumerate(test_loader, 0):\n",
        "        # print('iteration {}'.format(i))\n",
        "      \n",
        "        images, labels = data\n",
        "\n",
        "        images = images.to(device)  # <----------- And note it's NOT an in-place operation; original\n",
        "        labels = labels.to(device)  # <----------- variables still exist on CPU\n",
        "        \n",
        "        outputs = model_gpu(images)\n",
        "        \n",
        "        # torch.max is an argmax operation\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        # print(predicted.cpu())\n",
        "\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "        # Append batch prediction results\n",
        "        tot_predicted = torch.cat([tot_predicted, predicted.view(-1).cpu()])\n",
        "        tot_labels    = torch.cat([tot_labels,    labels.view(-1).cpu()])\n",
        "\n",
        "\n",
        "print('Accuracy of the network on the test images: %d %%' % (100 * correct / total))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the test images: 54 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z1F3FqdVY5wG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "e0bba9d4-20a3-4d52-df98-c7e1feb10f8e"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "cm = confusion_matrix(tot_labels.numpy(), tot_predicted.numpy())\n",
        "cm"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[109,   2,   7,  50,   2,   0,  13,   2,   2,   1],\n",
              "       [  7,  97,   1,  21,   7,   1,   9,  12,   8,  13],\n",
              "       [  2,   3, 123,   7,  16,   4,  13,   8,   8,   3],\n",
              "       [ 23,   5,   3, 119,   3,   2,   7,  10,   5,   1],\n",
              "       [  1,   5,   8,   2, 100,  11,  17,   5,  17,   3],\n",
              "       [  2,   4,   5,   8,  28,  59,  46,   7,  25,   0],\n",
              "       [  1,   2,   5,   6,  26,  11,  86,   8,  17,   0],\n",
              "       [  9,   9,  14,  19,  11,   3,  19,  84,  14,   6],\n",
              "       [  5,  11,   9,   7,  17,   3,  28,  12,  88,   2],\n",
              "       [  1,  30,   3,  10,   5,   0,   4,   2,   7, 124]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DCSUWZuPY9F0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import itertools\n",
        "\n",
        "def plot_confusion_matrix(cm,\n",
        "                          classes,\n",
        "                          normalize=False,\n",
        "                          title='Confusion matrix',\n",
        "                          cmap=plt.cm.Blues):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix very prettily.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        print(\"Normalized confusion matrix\")\n",
        "    else:\n",
        "        print('Confusion matrix, without normalization')\n",
        "\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "\n",
        "    # Specify the tick marks and axis text\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=90)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "\n",
        "    # The data formatting\n",
        "    fmt = '.2f' if normalize else 'd'\n",
        "    thresh = cm.max() / 2.\n",
        "    \n",
        "    # Print the text of the matrix, adjusting text colour for display\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, format(cm[i, j], fmt),\n",
        "                 horizontalalignment=\"center\",\n",
        "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9QK9HOnTY-bz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 314
        },
        "outputId": "a2dcdc58-a249-4b2d-ed6f-97daa97e6ede"
      },
      "source": [
        "plot_confusion_matrix(cm, np.arange(0,10))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion matrix, without normalization\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQgAAAEYCAYAAACgIGhkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}